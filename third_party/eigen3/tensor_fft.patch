diff --git a/unsupported/Eigen/CXX11/src/Tensor/TensorFFT.h b/unsupported/Eigen/CXX11/src/Tensor/TensorFFT.h
index 55c7d6831..c52a99d85 100644
--- a/unsupported/Eigen/CXX11/src/Tensor/TensorFFT.h
+++ b/unsupported/Eigen/CXX11/src/Tensor/TensorFFT.h
@@ -10,6 +10,11 @@
 #ifndef EIGEN_CXX11_TENSOR_TENSOR_FFT_H
 #define EIGEN_CXX11_TENSOR_TENSOR_FFT_H
 
+// This code requires the ability to initialize arrays of constant
+// values directly inside a class.
+#if __cplusplus >= 201103L || EIGEN_COMP_MSVC >= 1900
+#include <unsupported/Eigen/FFT>
+
 namespace Eigen {
 
 /** \class TensorFFT
@@ -214,6 +219,7 @@ struct TensorEvaluator<const TensorFFTOp<FFT, ArgType, FFTResultType, FFTDir>, D
 #endif
 
  private:
+  Eigen::FFT<RealScalar> fft_eigen;
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalToBuf(EvaluatorPointerType data) {
     const bool write_to_out = internal::is_same<OutputScalar, ComplexScalar>::value;
     ComplexScalar* buf = write_to_out ? (ComplexScalar*)data : (ComplexScalar*)m_device.allocate(sizeof(ComplexScalar) * m_size);
@@ -226,88 +232,37 @@ struct TensorEvaluator<const TensorFFTOp<FFT, ArgType, FFTResultType, FFTDir>, D
       Index dim = m_fft[i];
       eigen_assert(dim >= 0 && dim < NumDims);
       Index line_len = m_dimensions[dim];
-      eigen_assert(line_len >= 1);
+      eigen_assert(line_len > 1);
       ComplexScalar* line_buf = (ComplexScalar*)m_device.allocate(sizeof(ComplexScalar) * line_len);
-      const bool is_power_of_two = isPowerOfTwo(line_len);
-      const Index good_composite = is_power_of_two ? 0 : findGoodComposite(line_len);
-      const Index log_len = is_power_of_two ? getLog2(line_len) : getLog2(good_composite);
-
-      ComplexScalar* a = is_power_of_two ? NULL : (ComplexScalar*)m_device.allocate(sizeof(ComplexScalar) * good_composite);
-      ComplexScalar* b = is_power_of_two ? NULL : (ComplexScalar*)m_device.allocate(sizeof(ComplexScalar) * good_composite);
-      ComplexScalar* pos_j_base_powered = is_power_of_two ? NULL : (ComplexScalar*)m_device.allocate(sizeof(ComplexScalar) * (line_len + 1));
-      if (!is_power_of_two) {
-        // Compute twiddle factors
-        //   t_n = exp(sqrt(-1) * pi * n^2 / line_len)
-        // for n = 0, 1,..., line_len-1.
-        // For n > 2 we use the recurrence t_n = t_{n-1}^2 / t_{n-2} * t_1^2
-
-        // The recurrence is correct in exact arithmetic, but causes
-        // numerical issues for large transforms, especially in
-        // single-precision floating point.
-        //
-        // pos_j_base_powered[0] = ComplexScalar(1, 0);
-        // if (line_len > 1) {
-        //   const ComplexScalar pos_j_base = ComplexScalar(
-        //       numext::cos(M_PI / line_len), numext::sin(M_PI / line_len));
-        //   pos_j_base_powered[1] = pos_j_base;
-        //   if (line_len > 2) {
-        //     const ComplexScalar pos_j_base_sq = pos_j_base * pos_j_base;
-        //     for (int i = 2; i < line_len + 1; ++i) {
-        //       pos_j_base_powered[i] = pos_j_base_powered[i - 1] *
-        //           pos_j_base_powered[i - 1] /
-        //           pos_j_base_powered[i - 2] *
-        //           pos_j_base_sq;
-        //     }
-        //   }
-        // }
-        // TODO(rmlarsen): Find a way to use Eigen's vectorized sin
-        // and cosine functions here.
-        for (int j = 0; j < line_len + 1; ++j) {
-          double arg = ((EIGEN_PI * j) * j) / line_len;
-          std::complex<double> tmp(numext::cos(arg), numext::sin(arg));
-          pos_j_base_powered[j] = static_cast<ComplexScalar>(tmp);
-        }
-      }
+      ComplexScalar* temp_buf = (ComplexScalar*)m_device.allocate(sizeof(ComplexScalar) * line_len);
 
       for (Index partial_index = 0; partial_index < m_size / line_len; ++partial_index) {
         const Index base_offset = getBaseOffsetFromIndex(partial_index, dim);
 
-        // get data into line_buf
         const Index stride = m_strides[dim];
-        if (stride == 1) {
-          m_device.memcpy(line_buf, &buf[base_offset], line_len*sizeof(ComplexScalar));
-        } else {
-          Index offset = base_offset;
-          for (int j = 0; j < line_len; ++j, offset += stride) {
-            line_buf[j] = buf[offset];
-          }
-        }
-
-        // process the line
-        if (is_power_of_two) {
-          processDataLineCooleyTukey(line_buf, line_len, log_len);
-        }
-        else {
-          processDataLineBluestein(line_buf, line_len, good_composite, log_len, a, b, pos_j_base_powered);
-        }
-
-        // write back
-        if (FFTDir == FFT_FORWARD && stride == 1) {
-          m_device.memcpy(&buf[base_offset], line_buf, line_len*sizeof(ComplexScalar));
-        } else {
-          Index offset = base_offset;
-          const ComplexScalar div_factor =  ComplexScalar(1.0 / line_len, 0);
-          for (int j = 0; j < line_len; ++j, offset += stride) {
-             buf[offset] = (FFTDir == FFT_FORWARD) ? line_buf[j] : line_buf[j] * div_factor;
-          }
-        }
+	
+	if (stride == 1) 
+	{
+		memcpy(line_buf, &buf[base_offset], line_len*sizeof(ComplexScalar));
+		(FFTDir == FFT_FORWARD)? 
+			fft_eigen.fwd(&buf[base_offset],line_buf,line_len): 
+			fft_eigen.inv(&buf[base_offset],line_buf,line_len);
+	}else{
+		Index offset = base_offset;
+		for (int j = 0; j < line_len; ++j, offset += stride)
+			line_buf[j] = buf[offset];
+
+		(FFTDir == FFT_FORWARD) ? 
+			fft_eigen.fwd(temp_buf,line_buf,line_len): 
+			fft_eigen.inv(temp_buf,line_buf,line_len);
+
+		offset = base_offset;
+		for (int j = 0 ; j < line_len; ++j, offset += stride)
+			buf[offset] = temp_buf[j];
+	}
       }
       m_device.deallocate(line_buf);
-      if (!is_power_of_two) {
-        m_device.deallocate(a);
-        m_device.deallocate(b);
-        m_device.deallocate(pos_j_base_powered);
-      }
+      m_device.deallocate(temp_buf);
     }
 
     if(!write_to_out) {
@@ -318,6 +273,12 @@ struct TensorEvaluator<const TensorFFTOp<FFT, ArgType, FFTResultType, FFTDir>, D
     }
   }
 
+  //TODO: Add In-Place capability
+  //TODO: Remove PRESERVE_INPUT FLAG
+  //TODO: Cache plans
+  //TODO: Use FFTW
+  //TODO: Use FFT2D for 2d+ tensors
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE static bool isPowerOfTwo(Index x) {
     eigen_assert(x > 0);
     return !(x & (x - 1));
@@ -667,4 +628,7 @@ struct TensorEvaluator<const TensorFFTOp<FFT, ArgType, FFTResultType, FFTDir>, D
 
 }  // end namespace Eigen
 
+#endif  // EIGEN_HAS_CONSTEXPR
+
+
 #endif  // EIGEN_CXX11_TENSOR_TENSOR_FFT_H
diff --git a/unsupported/Eigen/FFT b/unsupported/Eigen/FFT
index d9ad21a5a..8236df6fe 100644
--- a/unsupported/Eigen/FFT
+++ b/unsupported/Eigen/FFT
@@ -81,9 +81,10 @@
 #elif defined EIGEN_MKL_DEFAULT
 // TODO 
 // intel Math Kernel Library: fastest, commercial -- may be incompatible with Eigen in GPL form
-#  include "src/FFT/ei_imklfft_impl.h"
+#  include "fftw/fftw3_mkl.h"
+#  include "src/FFT/ei_fftw_impl.h"
    namespace Eigen {
-     template <typename T> struct default_fft_impl : public internal::imklfft_impl {};
+     template <typename T> struct default_fft_impl : public internal::fftw_impl<T> {};
    }
 #else
 // internal::kissfft_impl:  small, free, reasonably efficient default, derived from kissfft
@@ -174,7 +175,12 @@ class FFT
       Speedy=32767
     };
 
-    FFT( const impl_type & impl=impl_type() , Flag flags=Default ) :m_impl(impl),m_flag(flags) { }
+    FFT( const impl_type & impl=impl_type() , Flag flags=Default ) :m_impl(impl),m_flag(flags) {
+
+#ifdef EIGEN_FFTW_DEFAULT
+     fftw_make_planner_thread_safe();
+#endif
+    }
 
     inline
     bool HasFlag(Flag f) const { return (m_flag & (int)f) == f;}
diff --git a/unsupported/test/cxx11_tensor_fft.cpp b/unsupported/test/cxx11_tensor_fft.cpp
index 641486a4a..f83196a14 100644
--- a/unsupported/test/cxx11_tensor_fft.cpp
+++ b/unsupported/test/cxx11_tensor_fft.cpp
@@ -9,6 +9,7 @@
 
 #include "main.h"
 #include <Eigen/CXX11/Tensor>
+#include <bench/BenchTimer.h>
 
 using Eigen::Tensor;
 
@@ -38,7 +39,8 @@ static void test_fft_2D_golden() {
 
   std::complex<float> c_offset = std::complex<float>(1.0, 1.0);
 
-  if (DataLayout == ColMajor) {
+  if (DataLayout == ColMajor) 
+  {
     VERIFY_IS_APPROX(output(0) + c_offset, output_golden[0] + c_offset);
     VERIFY_IS_APPROX(output(1) + c_offset, output_golden[1] + c_offset);
     VERIFY_IS_APPROX(output(2) + c_offset, output_golden[2] + c_offset);
@@ -113,6 +115,38 @@ static void test_fft_complex_input_golden() {
   }
 }
 
+
+template <size_t Repeats,size_t WindowSize, int DataLayout, typename RealScalar, bool isComplexInput, int FFTResultType, int FFTDirection,int TensorRank>
+static void bench_fft_large_input() {
+	Eigen::DSizes<ptrdiff_t, TensorRank> dimensions;
+	ptrdiff_t total_size = 1;
+	for (int i = 0; i < TensorRank-1; ++i) {
+		dimensions[i] = 3;
+		total_size *= dimensions[i];
+	}
+	dimensions[TensorRank-1] = WindowSize;
+	total_size *= dimensions[TensorRank-1];
+	const DSizes<ptrdiff_t, TensorRank> arr = dimensions;
+
+	typedef typename internal::conditional<isComplexInput == true, std::complex<RealScalar>, RealScalar>::type InputScalar;
+	typedef typename internal::conditional<FFTResultType == Eigen::BothParts, std::complex<RealScalar>, RealScalar>::type OutputScalar;
+	Tensor<InputScalar, TensorRank , DataLayout> input;
+	Tensor<OutputScalar, TensorRank , DataLayout> output;
+
+	input.resize(arr);
+	input.setRandom();
+
+	BenchTimer timerFFT;
+	timerFFT.reset();
+	timerFFT.start();
+	array<ptrdiff_t, 1> fft;
+	fft[0] = 0;
+	for (size_t i = 0; i < Repeats; i++)
+		output = input.template fft<FFTResultType, FFTDirection>(fft);
+	timerFFT.stop();
+	std::cout << "FFT x"  << Repeats << ": " << timerFFT.value() << "s\n";
+}
+
 static void test_fft_real_input_golden() {
   Tensor<float, 1, ColMajor> input(5);
   input(0) = 1.0;
@@ -181,7 +215,7 @@ static void test_fft_real_input_energy() {
   Eigen::DSizes<ptrdiff_t, TensorRank> dimensions;
   ptrdiff_t total_size = 1;
   for (int i = 0; i < TensorRank; ++i) {
-    dimensions[i] = rand() % 20 + 1;
+    dimensions[i] = rand() % 20 + 3;
     total_size *= dimensions[i];
   }
   const DSizes<ptrdiff_t, TensorRank> arr = dimensions;
@@ -205,9 +239,19 @@ static void test_fft_real_input_energy() {
     VERIFY_IS_EQUAL(output.dimension(i), input.dimension(i));
   }
 
+  //std::cout <<"input:";
+  //for (int i = 0; i < total_size; i++)
+  //        std::cout << input(i);
+  //std::cout <<"\n";
+
+  //std::cout <<"output:";
+  //for (int i = 0; i < total_size; i++)
+  //        std::cout << output(i);
+  //std::cout <<"\n";
+
   RealScalar energy_original = 0.0;
   RealScalar energy_after_fft = 0.0;
-
+  
   for (int i = 0; i < total_size; ++i) {
     energy_original += numext::abs2(input(i));
   }
@@ -301,4 +345,37 @@ EIGEN_DECLARE_TEST(cxx11_tensor_fft) {
 
     test_fft_non_power_of_2_round_trip<float>(7);
     test_fft_non_power_of_2_round_trip<double>(7);
+
+    bench_fft_large_input<1000,512,ColMajor, float, false,Eigen::BothParts, FFT_FORWARD,1> ();
+    bench_fft_large_input<1000,512,ColMajor, double, false,Eigen::BothParts, FFT_FORWARD,1> ();
+    bench_fft_large_input<1000,512,ColMajor, float, true,Eigen::BothParts, FFT_FORWARD,1> ();
+    bench_fft_large_input<1000,512,ColMajor, double, true,Eigen::BothParts, FFT_FORWARD,1> ();
+    bench_fft_large_input<1000,512,RowMajor, float, false,Eigen::BothParts, FFT_FORWARD,1> ();
+    bench_fft_large_input<1000,512,RowMajor, double, false,Eigen::BothParts, FFT_FORWARD,1> ();
+    bench_fft_large_input<1000,512,RowMajor, float, true,Eigen::BothParts, FFT_FORWARD,1> ();
+    bench_fft_large_input<1000,512,RowMajor, double, true,Eigen::BothParts, FFT_FORWARD,1> ();
+    bench_fft_large_input<1000,512,ColMajor, float, false,Eigen::BothParts, FFT_REVERSE,1> ();
+    bench_fft_large_input<1000,512,ColMajor, double, false,Eigen::BothParts, FFT_REVERSE,1> ();
+    bench_fft_large_input<1000,512,ColMajor, float, true,Eigen::BothParts, FFT_REVERSE,1> ();
+    bench_fft_large_input<1000,512,ColMajor, double, true,Eigen::BothParts, FFT_REVERSE,1> ();
+    bench_fft_large_input<1000,512,RowMajor, float, false,Eigen::BothParts, FFT_REVERSE,1> ();
+    bench_fft_large_input<1000,512,RowMajor, double, false,Eigen::BothParts, FFT_REVERSE,1> ();
+    bench_fft_large_input<1000,512,RowMajor, float, true,Eigen::BothParts, FFT_REVERSE,1> ();
+    bench_fft_large_input<1000,512,RowMajor, double, true,Eigen::BothParts, FFT_REVERSE,1> ();
+    bench_fft_large_input<1000,512,ColMajor, float, false,Eigen::RealPart, FFT_FORWARD,1> ();
+    bench_fft_large_input<1000,512,ColMajor, double, false,Eigen::RealPart, FFT_FORWARD,1> ();
+    bench_fft_large_input<1000,512,ColMajor, float, true,Eigen::RealPart, FFT_FORWARD,1> ();
+    bench_fft_large_input<1000,512,ColMajor, double, true,Eigen::RealPart, FFT_FORWARD,1> ();
+    bench_fft_large_input<1000,512,RowMajor, float, false,Eigen::RealPart, FFT_FORWARD,1> ();
+    bench_fft_large_input<1000,512,RowMajor, double, false,Eigen::RealPart, FFT_FORWARD,1> ();
+    bench_fft_large_input<1000,512,RowMajor, float, true,Eigen::RealPart, FFT_FORWARD,1> ();
+    bench_fft_large_input<1000,512,RowMajor, double, true,Eigen::RealPart, FFT_FORWARD,1> ();
+    bench_fft_large_input<1000,512,ColMajor, float, false,Eigen::RealPart, FFT_REVERSE,1> ();
+    bench_fft_large_input<1000,512,ColMajor, double, false,Eigen::RealPart, FFT_REVERSE,1> ();
+    bench_fft_large_input<1000,512,ColMajor, float, true,Eigen::RealPart, FFT_REVERSE,1> ();
+    bench_fft_large_input<1000,512,ColMajor, double, true,Eigen::RealPart, FFT_REVERSE,1> ();
+    bench_fft_large_input<1000,512,RowMajor, float, false,Eigen::RealPart, FFT_REVERSE,1> ();
+    bench_fft_large_input<1000,512,RowMajor, double, false,Eigen::RealPart, FFT_REVERSE,1> ();
+    bench_fft_large_input<1000,512,RowMajor, float, true,Eigen::RealPart, FFT_REVERSE,1> ();
+    bench_fft_large_input<1000,512,RowMajor, double, true,Eigen::RealPart, FFT_REVERSE,1> ();
 }
